# Promps Design Philosophy and Implementation Strategy

**Last Updated**: 2025-11-24
**Purpose**: Core design decisions and implementation roadmap for AI context preservation

---

## ğŸ¯ Project Purpose

Promps is a **DSL (Domain Specific Language) to Natural Language translator** for AI prompt generation.

### Core Concept
```
[Input] Simplified DSL (Internal Representation)
   â†“
_N:User ãŒ _N:Order ã‚’ ä½œæˆ
   â†“
[Processing] Syntax Analysis + Logic Check + Optimization
   â†“
[Output] Natural Language Prompt (for AI)
   â†“
"ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ³¨æ–‡ã‚’ä½œæˆã™ã‚‹æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚
Userã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨Orderã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®é–¢ä¿‚æ€§ã‚’è€ƒæ…®ã—ã€
é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚"
```

---

## ğŸ§  Thinking Methodology

### Data-Driven, Bottom-Up Approach

1. **Concrete First**: Start with actual data structures (tables, fields, objects)
2. **Drilldown**: Detailed analysis from concrete examples
3. **Bottom-Up**: Abstract patterns emerge naturally from data
4. **Cognitive Mapping**: Users discover DDD concepts organically

### Why This Works with AI

- **Context-based prompts**: Uses relationships (connectives) instead of isolated keywords
- **Relationship graphs**: AI understands connections between concepts
- **Scalable expressions**: OOP-like flexibility in prompt structure
- **Natural discovery**: Users learn patterns through practice, not theory

---

## ğŸ”‘ Critical Design Decision: _N: Prefix

### Purpose: AST-like Annotation System

The `_N:` prefix is **NOT** just a marker - it's a **syntactic annotation** similar to type information in compilers.

### Why _N: Exists

```rust
// Without _N: (Ambiguous)
"ãƒ¦ãƒ¼ã‚¶ãƒ¼ ãƒ‡ãƒ¼ã‚¿ ä¿å­˜"
â†’ Which are nouns? AI must infer â†’ Uncertainty

// With _N: (Explicit)
"_N:ãƒ¦ãƒ¼ã‚¶ãƒ¼ _N:ãƒ‡ãƒ¼ã‚¿ ä¿å­˜"
â†’ Nouns are definite â†’ Focus on logic check
â†’ Only need to analyze particles (ãŒã€ã‚’ã€ã«)
```

### Benefits for Logic Check

1. âœ… **Reliable noun extraction**: `is_noun == true` is guaranteed
2. âœ… **Particle analysis focus**: Don't need to infer parts of speech
3. âœ… **Pattern matching simplicity**: Nouns are pre-identified
4. âœ… **Future validation**: Foundation for semantic validation

### User Experience

**Phase 0 (CLI)**: Manual annotation - tedious but temporary
- `_N:User ãŒ _N:Order ã‚’ ä½œæˆ` â† User types manually
- Only used by developers for bootstrapping

**Phase 1+ (GUI)**: Automatic annotation - seamless
```javascript
// User drags "Noun Block" with text "User"
// â†“ Internally generates:
"_N:User"
// User never sees _N: prefix
```

---

## ğŸ“Š Responsibility Separation (Inter-App)

### What Promps DOES (Syntax Check)

1. âœ… **Token pattern validation**: Check if part-of-speech order is grammatically correct
2. âœ… **Noun relationship check**: Verify relationships between nouns are explicitly stated

### What Promps DOES NOT DO (Semantic Analysis)

âŒ **Meaning validation**: Whether "User creates Color" makes sense semantically
âŒ **Domain knowledge**: Whether User and Order relationship is appropriate
âŒ **Deep context**: Whether this sentence contradicts previous sentences (meaning-wise)

### Why This Matters

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Promps     â”‚ â† Syntax validation only
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Generated prompt
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AI/LLM     â”‚ â† Semantic understanding
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Reasoning**: No need to duplicate semantic analysis - that's the AI's job.

---

## ğŸ‡¯ğŸ‡µ Japanese Language Challenge

### Why Logic Check is the Bottleneck

**Problem**: Japanese has extreme word order flexibility

```
English (Fixed order):
"User creates Order" â† Subject-Verb-Object (SVO)
"Order creates User" â† Different meaning

Japanese (Free order):
"_N:ãƒ¦ãƒ¼ã‚¶ãƒ¼ ãŒ _N:æ³¨æ–‡ ã‚’ ä½œæˆã™ã‚‹"
"_N:æ³¨æ–‡ ã‚’ _N:ãƒ¦ãƒ¼ã‚¶ãƒ¼ ãŒ ä½œæˆã™ã‚‹"
"ä½œæˆã™ã‚‹ _N:æ³¨æ–‡ ã‚’ _N:ãƒ¦ãƒ¼ã‚¶ãƒ¼ ãŒ"
â†‘ All mean the same thing but different word order
```

### Challenges

1. **Word order variability**: A=B and B=A can be the same meaning
2. **Particle system**: åŠ©è© (ãŒã€ã‚’ã€ã«ã€ã§) determine noun roles
3. **Subject/predicate omission**: Common in Japanese, must infer from context
4. **Bidirectional relations**: "User ãŒ Order ã‚’ æŒã¤" â‰¡ "Order ã¯ User ã« å±ã™ã‚‹"

### Why _N: Helps

```
Without _N:
"ãƒ¦ãƒ¼ã‚¶ãƒ¼ ãŒ æ³¨æ–‡ ã‚’ ä½œæˆ"
â†’ Must infer which are nouns from particles
â†’ Double burden: part-of-speech + logic check

With _N:
"_N:ãƒ¦ãƒ¼ã‚¶ãƒ¼ ãŒ _N:æ³¨æ–‡ ã‚’ ä½œæˆ"
â†’ Nouns are known
â†’ Focus only on particle analysis
â†’ Can handle any word order
```

---

## ğŸ—ï¸ Architecture: Compiler AST Analogy

### Promps â‰ˆ Compiler Structure

| Compiler | Promps | Status |
|----------|--------|--------|
| Lexical Analysis (Lexer) | Tokenization (_N: identification) | âœ… Phase 0 |
| Syntax Analysis (Parser) | AST construction | ğŸ”œ Phase N |
| Syntax Validation | Pattern matching | ğŸ”œ Phase N |
| Semantic Analysis | - | âŒ AI/LLM responsibility |
| Type Checking | Noun relationship check | ğŸ”œ Phase N |
| Intermediate Representation | Normalized AST | ğŸ”œ Phase N+1 |
| Code Generation | Prompt output | âœ… Phase 0 |

### Current Implementation (Phase 0)

```rust
// Lexical tokens
struct PromptPart {
    is_noun: bool,  // Part-of-speech tag
    text: String,   // Token text
}

// Parsing rules
- Token delimiter: single space
- Sentence delimiter: double space (or more)
- Noun marking: _N: prefix anywhere in sentence
```

### Future Implementation (Phase N)

```rust
// AST structure
enum ASTNode {
    Sentence {
        subject: Option<Noun>,
        object: Option<Noun>,
        verb: Action,
        particles: Vec<Particle>,
    },
    // ...
}

// Pattern matching validation
fn validate_pattern(parts: &[PromptPart]) -> Result<()> {
    match extract_pattern(parts) {
        [Noun, Particle("ãŒ"), Noun, Particle("ã‚’"), Verb] => Ok(),
        [Noun, Particle("ã‚’"), Verb] => Ok(),
        // ... 50-100 patterns
        _ => Err(ValidationError::InvalidPattern)
    }
}
```

---

## ğŸ¯ Implementation Strategy

### Phase Breakdown

| Phase | Content | Difficulty | Estimated Time |
|-------|---------|-----------|----------------|
| Phase 0 | CLI implementation | â­ | 1 hour âœ… |
| Phase 1 | GUI (Blockly.js) | â­â­ | 2-3 hours |
| Phase 2 | Add block types | â­â­ | 1-2 hours |
| **Phase N** | **Logic Check (AST)** | **â­â­â­â­â­** | **Weeks to months** |
| Phase N+1 | Output optimization | â­â­â­ | Days |

### Phase N: The Bottleneck

**Why it's hard:**
1. Japanese word order flexibility
2. 50-100+ pattern combinations
3. Particle analysis complexity
4. Bidirectional relationship normalization

**Why it's manageable:**
- âœ… No semantic analysis needed (AI's job)
- âœ… Pattern matching only (no meaning inference)
- âœ… Can start with minimal patterns (5-10)
- âœ… Incremental expansion based on usage

**Fallback strategy:**
If too complex â†’ Restrict word order to canonical form (simplified language)

### Phase N Implementation Plan

```rust
// Step 1: Minimal patterns (5-10)
match pattern {
    [N, ãŒ, V] => Ok(),
    [N, ã‚’, V] => Ok(),
    [N, ãŒ, N, ã‚’, V] => Ok(),
    _ => Err("Unsupported pattern")
}

// Step 2: Incremental expansion
// Add commonly used patterns based on user feedback

// Step 3: Normalization
// Convert free word order to canonical form
normalize("[N, ã‚’, N, ãŒ, V]") â†’ "[N, ãŒ, N, ã‚’, V]"

// Step 4: Relationship validation
validate_noun_relationships() {
    if (nouns.len() >= 2 && !has_relational_particle()) {
        Err("Missing relationship marker")
    }
}
```

---

## ğŸ“ Logic Check Scope

### What to Validate

1. âœ… **Token pattern**: Part-of-speech order is grammatically correct
   - Example: `[N, ãŒ, N, ã‚’, V]` âœ“
   - Example: `[N, N, V]` âœ— (missing particles)

2. âœ… **Noun relationships**: Multiple nouns must have explicit relationships
   - Example: `"_N:User _N:Order ä½œæˆ"` âœ— (no particles)
   - Example: `"_N:User ãŒ _N:Order ã‚’ ä½œæˆ"` âœ“ (particles present)

3. âœ… **Particle correctness**: Particles match their grammatical roles
   - Example: `"ãŒ"` with subject position âœ“
   - Example: `"ã‚’"` with object position âœ“

### What NOT to Validate

âŒ Semantic meaning ("User creates Color" makes no sense)
âŒ Domain knowledge (User-Order relationship appropriateness)
âŒ Deep context (contradiction with previous sentences)

---

## ğŸš€ Current Status (Phase 0 Complete)

### Achievements

**Files Created:**
- `Cargo.toml`: Project configuration
- `src/main.rs`: ~110 lines, 7 tests (100% passing)
- `README.md`: Comprehensive documentation
- `.gitignore`: Rust project ignore patterns
- `LICENSE`: MIT License (2025 Yoshihiro NAKAHARA)
- Community files: CONTRIBUTING.md, CODE_OF_CONDUCT.md, SECURITY.md

**Features Implemented:**
- âœ… Space-delimited token parsing
- âœ… Double-space sentence delimiter
- âœ… `_N:` prefix for noun marking (anywhere in sentence)
- âœ… Multi-token sentence support
- âœ… Output to stdout and file
- âœ… Self-hosting capability (can generate prompts for its own development)

**Foundation Established:**
- âœ… Lexical analysis complete
- âœ… Noun identification reliable
- âœ… Token boundaries clear
- âœ… Sentence boundaries defined
- âœ… Flexible noun positioning

### Next Steps

**Phase 1**: GUI implementation with Blockly.js
- Visual block builder (Scratch-like)
- Automatic `_N:` annotation
- Drag-and-drop interface

**Phase N**: Logic check (AST-based validation)
- Pattern matching implementation
- Particle analysis
- Relationship validation

---

## ğŸ’¡ Key Insights

1. **_N: is not a marker, it's type information** (like compiler annotations)
2. **Logic check â‰  Semantic analysis** (syntax only, meaning is AI's job)
3. **Japanese complexity requires AST-like approach** (particle analysis + pattern matching)
4. **Phase 0 lays groundwork for Phase N** (reliable tokenization enables complex validation)
5. **Incremental implementation** (start minimal, expand based on usage)

---

## ğŸ¤– AI Collaboration Strategy

### Understanding AI's Probabilistic Nature

**Core Principle**: Modern AI/LLMs are based on statistical/probabilistic models, not deterministic logic.

**Implication**: Output variation is **inherent to the technology**, not a bug.

```
Same prompt: "Create a modal dialog"
â†“ Probabilistic AI Model â†“
Output A: <div class="modal-dialog">...
Output B: <div class="modal-popup">...
Output C: <div class="custom-modal">...
```

Each output is statistically valid, but structurally different â†’ Creates checking burden.

### Strategic Commonalization Approach

**Problem**: Reviewing and correcting AI output variations consumes significant energy.

**Solution**: Absorb variations through strategic commonalization.

#### Traditional Approach (High Energy Cost)
```
Generate UI â†’ Review â†’ Fix variations â†’ Repeat
â†“
Endless cycle of checking and fixing
Energy drain on every screen/component
```

#### Strategic Approach (Low Energy Cost)
```
1. Identify variation patterns
   - Modal structures vary
   - CSS class names vary
   - Button layouts vary

2. Create common modules
   - Modal class (standardized structure)
   - CSS standards (consistent naming)
   - Component templates (reusable patterns)

3. Instruct AI to use common modules
   - "Use the Modal class from modal.js"
   - Variations absorbed by module
   - Checking burden minimized
```

### Commonalization Granularity

**Flexibility**: Any granularity from 1 line to 100+ lines is valid for commonalization.

**Decision Criteria**:
- Cost of commonalization < Cost of repeated checking
- If duplication appears â†’ Commonalize immediately (not "later")
- Applies to: Code, UI components, CSS classes, modal structures, etc.

**Examples**:
- **Code**: Validation functions (password, username)
- **UI**: Modal class, form templates
- **CSS**: Standard class naming conventions
- **Patterns**: Event handlers, keyboard navigation

### Energy Preservation

**Rationale**: Developer energy is finite and precious.

**Trade-offs**:
- âœ… Spend energy on: Strategic commonalization, core logic, design decisions
- âŒ Don't spend energy on: Checking AI output variations, fixing cosmetic differences

**Result**: Energy preserved for essential thinking, not repetitive checking.

### Real-World Validation (KakeiBon)

**Achievement**: 525 tests, 100% success rate

**Why it worked**:
- Modal class absorbed UI variations
- Validation helpers absorbed logic variations
- CSS standards absorbed styling variations
- Common patterns absorbed structural variations

**Impact**: Minimal hand-back, rare specification changes, consistent quality.

### Best Practices for AI Collaboration

1. **Understand the technology**: AI is probabilistic â†’ Variations are normal
2. **See duplication, fix immediately**: Don't defer commonalization
3. **Any granularity is valid**: 1 line or 100 lines, commonalize if cost-effective
4. **Strategic, not reactive**: Anticipate variation points, commonalize proactively
5. **Preserve energy**: Automate checking through commonalization

### Why This Matters for Promps

Promps itself generates prompts for AI â†’ Understanding AI's probabilistic nature is **essential**.

- **Input**: DSL with clear structure (_N: annotations)
- **Output**: Natural language for probabilistic AI
- **Strategy**: Syntax validation only (let AI handle semantic variations)

By separating syntax (Promps) from semantics (AI), we allow AI to use its probabilistic strength (understanding meaning) while ensuring structural consistency through validation.

---

## ğŸ¨ Business Model

**Open Core Strategy:**
- Phase 0-2: MIT License (Open Source, Free)
- Future Pro Version: Proprietary (Advanced features, Enterprise support)

Repository will remain private initially, can be made public later.

---

**This document ensures design continuity across sessions and prevents knowledge loss during context compression.**
